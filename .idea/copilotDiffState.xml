<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/app.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app.py" />
              <option name="originalContent" value="import os&#10;import tarfile&#10;import zipfile&#10;from glob import glob&#10;import matplotlib.pylab as plt&#10;import numpy as np&#10;import time&#10;from functools import partial&#10;from multiprocessing import Pool, cpu_count&#10;&#10;from backend.convolve import convolve&#10;from backend.filter_generation import generate_filter&#10;from backend.max_pool import max_pool&#10;&#10;from flask import Flask, render_template, request&#10;&#10;filename1 = None&#10;filename2 = None&#10;&#10;app = Flask(__name__)&#10;&#10;@app.route('/')&#10;def hello_world():&#10;    return render_template('index.html')&#10;&#10;@app.route('/upload', methods=['POST'])&#10;def upload_files():&#10;    uploaded_file1 = request.files.get('zipfile')&#10;    uploaded_file2 = request.files.get('zipfile2')&#10;    messages = []&#10;&#10;    # Dataset one&#10;    if uploaded_file1 and uploaded_file1.filename:&#10;        global filename1&#10;        filename1 = uploaded_file1.filename&#10;        upload_path1 = os.path.join(app.static_folder, 'uploads1', filename1)&#10;        extract_path1 = os.path.join(app.static_folder, 'extracted_files1')&#10;        os.makedirs(os.path.dirname(upload_path1), exist_ok=True)&#10;        os.makedirs(extract_path1, exist_ok=True)&#10;        uploaded_file1.save(upload_path1)&#10;        if filename1.endswith('.zip'):&#10;            with zipfile.ZipFile(upload_path1, 'r') as zip_ref:&#10;                zip_ref.extractall(extract_path1)&#10;            messages.append('Dataset one: Zip file processed and extracted.')&#10;        elif filename1.endswith('.tar.gz') or filename1.endswith('.tar.xz'):&#10;            mode = 'r:gz' if filename1.endswith('.tar.gz') else 'r:xz'&#10;            with tarfile.open(upload_path1, mode) as tar_ref:&#10;                tar_ref.extractall(extract_path1)&#10;            messages.append(f'Dataset one: {os.path.splitext(filename1)[1]} file processed and extracted.')&#10;        else:&#10;            messages.append('Dataset one: Invalid file type.')&#10;    else:&#10;        messages.append('Dataset one: No file uploaded.')&#10;&#10;    # Dataset two&#10;    if uploaded_file2 and uploaded_file2.filename:&#10;        global filename2&#10;        filename2 = uploaded_file2.filename&#10;        upload_path2 = os.path.join(app.static_folder, 'uploads2', filename2)&#10;        extract_path2 = os.path.join(app.static_folder, 'extracted_files2')&#10;        os.makedirs(os.path.dirname(upload_path2), exist_ok=True)&#10;        os.makedirs(extract_path2, exist_ok=True)&#10;        uploaded_file2.save(upload_path2)&#10;        if filename2.endswith('.zip'):&#10;            with zipfile.ZipFile(upload_path2, 'r') as zip_ref:&#10;                zip_ref.extractall(extract_path2)&#10;            messages.append('Dataset two: Zip file processed and extracted.')&#10;        elif filename2.endswith('.tar.gz') or filename2.endswith('.tar.xz'):&#10;            mode = 'r:gz' if filename2.endswith('.tar.gz') else 'r:xz'&#10;            with tarfile.open(upload_path2, mode) as tar_ref:&#10;                tar_ref.extractall(extract_path2)&#10;            messages.append(f'Dataset two: {os.path.splitext(filename2)[1]} file processed and extracted.')&#10;        else:&#10;            messages.append('Dataset two: Invalid file type.')&#10;    else:&#10;        messages.append('Dataset two: No file uploaded.')&#10;&#10;    trainbutton = &quot;&lt;a href='/train' id='trainButton' style='width:75%'&gt;&lt;button&gt;Train Model&lt;/button&gt;&lt;/a&gt;&quot;&#10;&#10;    filename1 = os.path.splitext(filename1)[0]&#10;    filename2 = os.path.splitext(filename2)[0]&#10;&#10;    return render_template('index.html', trainbutton=trainbutton, message=' '.join(messages))&#10;&#10;def process_image(image_path, layers):&#10;    &quot;&quot;&quot;Processes a single image through all layers.&quot;&quot;&quot;&#10;    pixelinfo = plt.imread(image_path)&#10;    normal_maps = [[] for _ in range(len(layers))]&#10;&#10;    # Layer 0&#10;    out_channels_layer0 = layers[0].shape[3]&#10;    for j in range(out_channels_layer0):&#10;        filter_slice = layers[0][:, :, :, j]&#10;        normal_map = convolve(pixelinfo, filter_slice)&#10;        normal_map = np.maximum(0, normal_map)&#10;        normal_map = max_pool(normal_map, pool_size=2, stride=2)&#10;        normal_maps[0].append(normal_map)&#10;&#10;    # Subsequent layers&#10;    for i in range(1, len(layers)):&#10;        input_maps = np.concatenate(normal_maps[i-1], axis=-1)&#10;        out_channels = layers[i].shape[3]&#10;        for j in range(out_channels):&#10;            filter_slice = layers[i][:, :, :, j]&#10;            normal_map = convolve(input_maps, filter_slice)&#10;            normal_map = np.maximum(0, normal_map)&#10;            normal_map = max_pool(normal_map, pool_size=2, stride=2)&#10;            normal_maps[i].append(normal_map)&#10;&#10;    # Return the final feature maps for the image&#10;    return normal_maps&#10;&#10;@app.route('/train', methods=['GET'])&#10;def train_model():&#10;    global filename1, filename2&#10;    upload1_images = glob(os.path.join(app.static_folder, 'extracted_files1', filename1, '*'))&#10;    upload2_images = glob(os.path.join(app.static_folder, 'extracted_files2', filename2, '*'))&#10;&#10;    filter_height = 3&#10;    filter_width = 3&#10;    in_channels = 3&#10;    out_channels = 16&#10;&#10;    layers = []&#10;    for i in range(5):&#10;        layer = generate_filter(filter_height, filter_width, in_channels, out_channels)&#10;        layers.append(layer)&#10;        print(f&quot;Generated filters for layer {i + 1} with shape: {layer.shape}&quot;)&#10;        # For subsequent layers, in_channels will be the out_channels of the previous one&#10;        in_channels = out_channels&#10;        out_channels *= 2&#10;&#10;    print(&quot;Generated filters for 5 layers.&quot;)&#10;    startTime = time.time()&#10;&#10;    # Use multiprocessing to process images in parallel&#10;    num_processes = cpu_count()&#10;    print(f&quot;Starting image processing with {num_processes} processes...&quot;)&#10;&#10;    with Pool(processes=num_processes) as pool:&#10;        # We use partial to pass the 'layers' argument to process_image&#10;        process_func = partial(process_image, layers=layers)&#10;&#10;        print(&quot;Processing dataset 1...&quot;)&#10;        results1 = pool.map(process_func, upload1_images)&#10;&#10;        print(&quot;Processing dataset 2...&quot;)&#10;        results2 = pool.map(process_func, upload2_images)&#10;&#10;    endTime = time.time()&#10;    print(f&quot;Finished processing all images in {endTime - startTime:.2f} seconds.&quot;)&#10;&#10;    # `results1` and `results2` now contain the processed feature maps for each image&#10;    # Example: access the first image's final layer's first feature map&#10;    if results1:&#10;        print(&quot;Shape of a final feature map from dataset 1:&quot;, results1[0][-1][0].shape)&#10;&#10;&#10;    return render_template('index.html', message='Training complete.')&#10;&#10;if __name__ == '__main__':&#10;    app.run(debug=True)" />
              <option name="updatedContent" value="import os&#10;import tarfile&#10;import zipfile&#10;from glob import glob&#10;import matplotlib.pylab as plt&#10;import numpy as np&#10;import time&#10;from functools import partial&#10;from multiprocessing import Pool, cpu_count&#10;&#10;from backend.convolve import convolve&#10;from backend.filter_generation import generate_filter&#10;from backend.max_pool import max_pool&#10;&#10;from flask import Flask, render_template, request&#10;&#10;filename1 = None&#10;filename2 = None&#10;&#10;app = Flask(__name__)&#10;&#10;@app.route('/')&#10;def hello_world():&#10;    return render_template('index.html')&#10;&#10;@app.route('/upload', methods=['POST'])&#10;def upload_files():&#10;    uploaded_file1 = request.files.get('zipfile')&#10;    uploaded_file2 = request.files.get('zipfile2')&#10;    messages = []&#10;&#10;    # Dataset one&#10;    if uploaded_file1 and uploaded_file1.filename:&#10;        global filename1&#10;        filename1 = uploaded_file1.filename&#10;        upload_path1 = os.path.join(app.static_folder, 'uploads1', filename1)&#10;        extract_path1 = os.path.join(app.static_folder, 'extracted_files1')&#10;        os.makedirs(os.path.dirname(upload_path1), exist_ok=True)&#10;        os.makedirs(extract_path1, exist_ok=True)&#10;        uploaded_file1.save(upload_path1)&#10;        if filename1.endswith('.zip'):&#10;            with zipfile.ZipFile(upload_path1, 'r') as zip_ref:&#10;                zip_ref.extractall(extract_path1)&#10;            messages.append('Dataset one: Zip file processed and extracted.')&#10;        elif filename1.endswith('.tar.gz') or filename1.endswith('.tar.xz'):&#10;            mode = 'r:gz' if filename1.endswith('.tar.gz') else 'r:xz'&#10;            with tarfile.open(upload_path1, mode) as tar_ref:&#10;                tar_ref.extractall(extract_path1)&#10;            messages.append(f'Dataset one: {os.path.splitext(filename1)[1]} file processed and extracted.')&#10;        else:&#10;            messages.append('Dataset one: Invalid file type.')&#10;    else:&#10;        messages.append('Dataset one: No file uploaded.')&#10;&#10;    # Dataset two&#10;    if uploaded_file2 and uploaded_file2.filename:&#10;        global filename2&#10;        filename2 = uploaded_file2.filename&#10;        upload_path2 = os.path.join(app.static_folder, 'uploads2', filename2)&#10;        extract_path2 = os.path.join(app.static_folder, 'extracted_files2')&#10;        os.makedirs(os.path.dirname(upload_path2), exist_ok=True)&#10;        os.makedirs(extract_path2, exist_ok=True)&#10;        uploaded_file2.save(upload_path2)&#10;        if filename2.endswith('.zip'):&#10;            with zipfile.ZipFile(upload_path2, 'r') as zip_ref:&#10;                zip_ref.extractall(extract_path2)&#10;            messages.append('Dataset two: Zip file processed and extracted.')&#10;        elif filename2.endswith('.tar.gz') or filename2.endswith('.tar.xz'):&#10;            mode = 'r:gz' if filename2.endswith('.tar.gz') else 'r:xz'&#10;            with tarfile.open(upload_path2, mode) as tar_ref:&#10;                tar_ref.extractall(extract_path2)&#10;            messages.append(f'Dataset two: {os.path.splitext(filename2)[1]} file processed and extracted.')&#10;        else:&#10;            messages.append('Dataset two: Invalid file type.')&#10;    else:&#10;        messages.append('Dataset two: No file uploaded.')&#10;&#10;    trainbutton = &quot;&lt;a href='/train' id='trainButton' style='width:75%'&gt;&lt;button&gt;Train Model&lt;/button&gt;&lt;/a&gt;&quot;&#10;&#10;    filename1 = os.path.splitext(filename1)[0]&#10;    filename2 = os.path.splitext(filename2)[0]&#10;&#10;    return render_template('index.html', trainbutton=trainbutton, message=' '.join(messages))&#10;&#10;def process_image(image_path, layers):&#10;    &quot;&quot;&quot;Processes a single image through all layers.&quot;&quot;&quot;&#10;    pixelinfo = plt.imread(image_path)&#10;    normal_maps = [[] for _ in range(len(layers))]&#10;&#10;    # Layer 0&#10;    out_channels_layer0 = layers[0].shape[3]&#10;    for j in range(out_channels_layer0):&#10;        filter_slice = layers[0][:, :, :, j]&#10;        normal_map = convolve(pixelinfo, filter_slice) # Output is 2D&#10;        normal_map = np.maximum(0, normal_map)&#10;        # Add channel dimension for max_pool&#10;        normal_map = max_pool(normal_map[:, :, np.newaxis], pool_size=2, stride=2)&#10;        normal_maps[0].append(normal_map)&#10;&#10;    # Subsequent layers&#10;    for i in range(1, len(layers)):&#10;        # Concatenate along the channel axis&#10;        input_maps = np.concatenate(normal_maps[i-1], axis=-1)&#10;        out_channels = layers[i].shape[3]&#10;        for j in range(out_channels):&#10;            filter_slice = layers[i][:, :, :, j]&#10;            normal_map = convolve(input_maps, filter_slice) # Output is 2D&#10;            normal_map = np.maximum(0, normal_map)&#10;            # Add channel dimension for max_pool&#10;            normal_map = max_pool(normal_map[:, :, np.newaxis], pool_size=2, stride=2)&#10;            normal_maps[i].append(normal_map)&#10;&#10;    # Return the final feature maps for the image&#10;    return normal_maps&#10;&#10;@app.route('/train', methods=['GET'])&#10;def train_model():&#10;    global filename1, filename2&#10;    upload1_images = glob(os.path.join(app.static_folder, 'extracted_files1', filename1, '*'))&#10;    upload2_images = glob(os.path.join(app.static_folder, 'extracted_files2', filename2, '*'))&#10;&#10;    filter_height = 3&#10;    filter_width = 3&#10;    in_channels = 3&#10;    out_channels = 16&#10;&#10;    layers = []&#10;    for i in range(5):&#10;        layer = generate_filter(filter_height, filter_width, in_channels, out_channels)&#10;        layers.append(layer)&#10;        print(f&quot;Generated filters for layer {i + 1} with shape: {layer.shape}&quot;)&#10;        # For subsequent layers, in_channels will be the out_channels of the previous one&#10;        in_channels = out_channels&#10;        out_channels *= 2&#10;&#10;    print(&quot;Generated filters for 5 layers.&quot;)&#10;    startTime = time.time()&#10;&#10;    # Use multiprocessing to process images in parallel&#10;    num_processes = cpu_count()&#10;    print(f&quot;Starting image processing with {num_processes} processes...&quot;)&#10;&#10;    with Pool(processes=num_processes) as pool:&#10;        # We use partial to pass the 'layers' argument to process_image&#10;        process_func = partial(process_image, layers=layers)&#10;&#10;        print(&quot;Processing dataset 1...&quot;)&#10;        results1 = pool.map(process_func, upload1_images)&#10;&#10;        print(&quot;Processing dataset 2...&quot;)&#10;        results2 = pool.map(process_func, upload2_images)&#10;&#10;    endTime = time.time()&#10;    print(f&quot;Finished processing all images in {endTime - startTime:.2f} seconds.&quot;)&#10;&#10;    # `results1` and `results2` now contain the processed feature maps for each image&#10;    # Example: access the first image's final layer's first feature map&#10;    if results1:&#10;        print(&quot;Shape of a final feature map from dataset 1:&quot;, results1[0][-1][0].shape)&#10;&#10;&#10;    return render_template('index.html', message='Training complete.')&#10;&#10;if __name__ == '__main__':&#10;    app.run(debug=True)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/backend/convolve.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/backend/convolve.py" />
              <option name="originalContent" value="import time&#10;&#10;import numpy as np&#10;from numpy.lib.stride_tricks import as_strided&#10;&#10;def convolve(image, conv_filter):&#10;    filter_height, filter_width, in_channels = conv_filter.shape&#10;    img_height, img_width, img_channels = image.shape&#10;&#10;    assert in_channels == img_channels, &quot;Filter and image must have the same number of channels.&quot;&#10;&#10;    pad_h = (filter_height - 1) // 2&#10;    pad_w = (filter_width - 1) // 2&#10;&#10;    padded_image = np.pad(&#10;        image,&#10;        ((pad_h, pad_h), (pad_w, pad_w), (0, 0)),&#10;        mode='constant'&#10;    )&#10;&#10;    # Use stride_tricks to create a view of the image with sliding windows&#10;    # This avoids explicit loops and is much faster&#10;    view_shape = (img_height, img_width, filter_height, filter_width, in_channels)&#10;    strides = padded_image.strides[:2] + padded_image.strides&#10;    sub_matrices = as_strided(padded_image, shape=view_shape, strides=strides)&#10;&#10;    # Perform convolution using vectorized operations (einsum is great for this)&#10;    # This computes the sum of the element-wise product of the windows and the filter&#10;    output = np.einsum('h w H W c, H W c -&gt; h w c', sub_matrices, conv_filter)&#10;&#10;    return output" />
              <option name="updatedContent" value="import time&#10;&#10;import numpy as np&#10;from numpy.lib.stride_tricks import as_strided&#10;&#10;def convolve(image, conv_filter):&#10;    filter_height, filter_width, in_channels = conv_filter.shape&#10;    img_height, img_width, img_channels = image.shape&#10;&#10;    assert in_channels == img_channels, &quot;Filter and image must have the same number of channels.&quot;&#10;&#10;    pad_h = (filter_height - 1) // 2&#10;    pad_w = (filter_width - 1) // 2&#10;&#10;    padded_image = np.pad(&#10;        image,&#10;        ((pad_h, pad_h), (pad_w, pad_w), (0, 0)),&#10;        mode='constant'&#10;    )&#10;&#10;    # Use stride_tricks to create a view of the image with sliding windows&#10;    # This avoids explicit loops and is much faster&#10;    view_shape = (img_height, img_width, filter_height, filter_width, in_channels)&#10;    strides = padded_image.strides[:2] + padded_image.strides&#10;    sub_matrices = as_strided(padded_image, shape=view_shape, strides=strides)&#10;&#10;    # Perform convolution using vectorized operations (einsum is great for this)&#10;    # This computes the sum of the element-wise product of the windows and the filter&#10;    # The output should be 2D (h, w) for a single filter application.&#10;    output = np.einsum('h w H W c, H W c -&gt; h w', sub_matrices, conv_filter)&#10;&#10;    return output" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/backend/max_pool.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/backend/max_pool.py" />
              <option name="originalContent" value="import numpy as np&#10;&#10;def max_pool(image, pool_size=2, stride=2):&#10;    img_height, img_width, channels = image.shape&#10;    out_height = (img_height - pool_size) // stride + 1&#10;    out_width = (img_width - pool_size) // stride + 1&#10;    pooled = np.zeros((out_height, out_width, channels))&#10;&#10;    for c in range(channels):&#10;        for i in range(out_height):&#10;            for j in range(out_width):&#10;                h_start = i * stride&#10;                w_start = j * stride&#10;                window = image[h_start:h_start+pool_size, w_start:w_start+pool_size, c]&#10;                pooled[i, j, c] = np.max(window)&#10;    return pooled" />
              <option name="updatedContent" value="import numpy as np&#10;from numpy.lib.stride_tricks import as_strided&#10;&#10;def max_pool(image, pool_size=2, stride=2):&#10;    img_height, img_width, channels = image.shape&#10;    out_height = (img_height - pool_size) // stride + 1&#10;    out_width = (img_width - pool_size) // stride + 1&#10;&#10;    # Create a view of the image with sliding windows&#10;    view_shape = (out_height, out_width, channels, pool_size, pool_size)&#10;    &#10;    # Calculate strides for the view&#10;    # Stride for height, width, channels, then inside the pool window&#10;    strides = (&#10;        stride * image.strides[0], &#10;        stride * image.strides[1], &#10;        image.strides[2], &#10;        image.strides[0], &#10;        image.strides[1]&#10;    )&#10;    &#10;    windows = as_strided(image, shape=view_shape, strides=strides)&#10;&#10;    # Find the maximum value in each window across the pool_size x pool_size dimensions&#10;    # The axes to reduce are the last two (pool_height and pool_width)&#10;    pooled = np.max(windows, axis=(3, 4))&#10;    &#10;    return pooled" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>